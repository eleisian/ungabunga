# Contributing to Ungabunga

Thank you for your interest in contributing to Ungabunga! This project aims to develop a dense, symbolic language for efficient knowledge transfer, and we welcome contributions from the community.

## How Can I Contribute?

- **Vocabulary Expansion**: Add new tokens to `vocab.json` for geography or other domains.
- **Syntax Improvements**: Propose enhancements to syntax rules in `docs/syntax.md`.
- **Tokenizer Development**: Improve `ungabunga_tokenizer.py` to handle new token types or syntax.
- **Dataset Contributions**: Expand datasets in `src/dataset/` with more facts in Ungabunga, RDF, or natural language formats.
- **Model Fine-Tuning**: Enhance the fine-tuning scripts in `src/model/` or suggest new models for testing.
- **Information Theory Metrics**: Contribute to entropy or bits-per-token calculations in `src/metrics/`.
- **Documentation**: Improve clarity in `docs/` for vocabulary, syntax, or evaluation metrics.
- **Tests and Demos**: Add unit tests in `tests/` or example scripts in `examples/`.

## Contribution Guidelines

1. **Fork the Repository**: Create your own fork of the code.
2. **Make Changes**: Implement your changes in your fork.
3. **Test Your Changes**: Make sure your changes don't break existing functionality. Add tests if applicable.
4. **Submit a Pull Request**: Create a PR with a clear description of your changes and why they are necessary.
5. **Code Review**: Your PR will be reviewed by maintainers. Address any feedback provided.

## Issues

Feel free to open issues for:
- Expanding vocabulary to 100 tokens.
- Adding support for new domains (e.g., science).
- Implementing new entropy metrics.
- Suggestions for nested syntax parsing or other features.

## Community

Join discussions on relevant forums or follow updates on X (details to be added).

We look forward to your contributions!
